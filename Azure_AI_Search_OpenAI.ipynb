{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ⚡️ Quick Overview\n",
    "Followed this [LangChain documentation](https://python.langchain.com/v0.1/docs/integrations/vectorstores/azuresearch/) with several tricks, testing, and refinement. \n",
    "\n",
    "Overall this is a simple RAG flow based on Azure AI Search and Azure Document Intelligence (reading a word document in this case). It uses OpenAI Embedding model (unfortunately it is forced to be used by Azure AI Search) to create the embedding, creates an index (like a retriever) in Azure AI Search, load a chunked document into the created Azure AI Search object, and perform semantic search utlising the created indexer. The downside is, this script did not create a persistent vector database within Azure as it would require blob storage, which needs another subscription. \n",
    "\n",
    "Code snippets from [Azure AI Document Intelligence](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/office_file/) and [LangChain's TextSplitter and tiktoken](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/split_by_token/) were used to load and chunk the text document\n",
    "\n",
    "Notes: It used OpenAI embedding model only, didn't involve LLM response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 24.1.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --quiet azure-search-documents\n",
    "!pip install --quiet azure-identity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_community.vectorstores.azuresearch import AzureSearch\n",
    "from langchain_openai import AzureOpenAIEmbeddings, OpenAIEmbeddings    # this langchain integration doesn't work\n",
    "from openai import OpenAI\n",
    "from dotenv import dotenv_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = dotenv_values(\".env\")\n",
    "openai_api_key: str = config['OPENAI_API_KEY']\n",
    "os.environ[\"OPENAI_API_KEY\"] = openai_api_key\n",
    "\n",
    "openai_api_version: str = \"2023-05-15\"\n",
    "model: str = \"text-embedding-ada-002\"\n",
    "\n",
    "vector_store_address: str = config[\"AZURE_AI_SEARCH_ENDPOINT\"]\n",
    "vector_store_password: str = config['AZURE_AI_SEARCH_API_KEY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#// Outdated method to pull openai embeddings via LangChain! Use OpenAI API directly instead\n",
    "# embeddings: OpenAIEmbeddings = OpenAIEmbeddings(\n",
    "#     openai_api_key=openai_api_key, openai_api_version=openai_api_version, model=model\n",
    "# )\n",
    "\n",
    "client = OpenAI()\n",
    "def get_embedding(text, model=\"text-embedding-3-small\"):\n",
    "   text = text.replace(\"\\n\", \" \")\n",
    "   return client.embeddings.create(input = [text], model=model).data[0].embedding\n",
    "\n",
    "index_name: str = \"langchain-vector-demo\"\n",
    "vector_store: AzureSearch = AzureSearch(\n",
    "    azure_search_endpoint=vector_store_address,\n",
    "    azure_search_key=vector_store_password,\n",
    "    index_name=index_name,\n",
    "    embedding_function=get_embedding)     # need to create a embedding function ahead to instantiate the AzureSearch object "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(page_content='Daniel Wong BSc (Hons), MSc\\n\\nGraduate Cost & Carbon Intelligence Consultant\\n\\n| Proposed position on project Bespoke to opportunity we are bidding for | Qualifications BSc (Hons) Environmental & Occupational Safety and Health Year completed: 2019 MSc Computing and Information System (Distinction) Year completed: 2022 | Professional memberships Publications Financial Risk Manager (FRM) Part 1 Certified (GARP) Certified ISO9001 Internal Auditor (HKQAA) Certificate in First Aid & adult CPR & automated external defibrillation (St. John) Completed training for Oracle Primavera P6 | |\\n| - | - | - | - |\\n| Project name Name of project we are bidding for ||||\\n\\nDaniel is a graduate consultant with a passion for innovation across industries. He consistently navigates new challenges with ease, demonstrating an exceptional capacity to adapt swiftly and devise innovative solutions to solve problems. Moreover, Daniel possesses a deep understanding and proficiency in leveraging cutting-edge technologies such as Large Language Models (LLM) and machine learning, further enhancing his capabilities to tackle diverse and complex tasks in the most efficient way as possible.\\n\\nRelevant experience\\n\\nDaniel\\'s career began in the oil and gas sector, where he quickly made a name for himself as a corporate HSSE advisor. Throughout his career, he has consistently taken on new challenges and expanded his skill set. This led him to pursue opportunities in a variety of industries, including energy, infrastructure, finance and logistics, where he was able to apply his skills to a range of different challenges.\\n\\nDaniel\\'s exceptional learning abilities have also been an asset in his professional development. He is always eager to take on new opportunities and continuously improve his skills and has pursued advanced education and training in a variety of fields.\\n\\nHe is a highly motivated and results-driven professional who is committed to making a positive impact in his work and community. He is a quick learner and problem solver who is always up for a challenge and eager to help others succeed.\\n\\nKey Skills\\n\\nPython\\n\\nMicrosoft Azure SQL\\n\\nLLM / Machine Learning\\n\\nWeb Development\\n\\nData Analytics & Visualisation\\n\\nProject experience\\n\\nNews Scraping Analytics App\\n\\nPotential Client: Anglian Water\\n\\nValue: Developed a web app to provide potential clients like Anglian Water with a tool to stay updated on the latest news and trends across the web related to their suppliers and focus areas.\\n\\nDates: Jan 2024 – Present\\n\\nRole: Full Stack/Web Developer\\n\\nDaniel initiated the project by creating a demo using Dash and later transitioned to Streamlit for the enhanced user interface and full-scale development. Additionally, Daniel integrated an LLM-powered chatbot (Llama2) and advanced RAG (Retrieval Augmented Generation) techniques to deliver relevant and accurate responses based on real-time information scraped from the internet. He also incorporated advanced analysis features such as text summarisation, sentiment analysis, and topic modelling for the scrapped news articles. Furthermore, Daniel implemented efficient data management using an SQL database and explored deployment options on Azure Web App service.\\n\\nMoJ – Asset Data Consolidation and Visualisation\\n\\nClient: Ministry of Justice (MoJ) - Prison Estate\\n\\nValue: Developed a comprehensive tool for consolidating and visualizing asset data to assist MoJ in strategic planning for their prison estates.\\n\\nDates: Mar 2024 – May 2024\\n\\nRole: Analyst, Data Analytics & Visualization\\n\\nAs the technical key driver, Daniel spearheaded the development of a customized ETL pipeline using Python to consolidate 440 datasets from 110 sites into a unified database. Afterward, he designed a dynamic Power BI dashboard to visualize these data sets, enabling MoJ to easily identify trends and make informed decisions regarding future asset management and capital works. This project showcased his ability to manage large data sets, standardize complex information, and deliver actionable insights through advanced data visualization tools.\\n\\nSmart Buildings Value Framework\\n\\nClient: Defence Infrastructure Organisation\\n\\nValue: Developed a dynamic framework tool that will serve as a useful tool for DIO to explore the potential benefits of adopting smart technologies at differing levels of sophistication.\\n\\nDates: Feb 2024 – Mar 2024\\n\\nRole: Analyst, Cost Management\\n\\nDaniel created a dynamic calculator to evaluate smart technology benefits in building infrastructure. He collaborated closely with stakeholders to meet requirements, designed algorithms to quantify six key benefits (i.e. water, electricity, gas, user experience, cost, and carbon), and utilised Excel\\'s advanced features like VBA and Power Pivot to develop an interactive and scalable dashboard in Excel.\\n\\nOptions Benchmarking\\n\\nClient: Scottish Water\\n\\nValue: Generated high level benchmark values for 7 options proposed for the East Sterling Villages projects, so as to support the client’s decision making on progressing their preferred option.\\n\\nDates: Oct 2023 – Dec 2023\\n\\nRole: Analyst, Cost Management\\n\\nDaniel was responsible for designing and implementing a mapping approach to compare Scottish Water\\'s provided models with AECOM internal models. His tasks included data cleaning, transformation, and the development of a VBA script to systematically benchmark the options. He conducted statistical validation to ensure the accuracy and reliability of the benchmarking process. Additionally, Daniel created a range of output values under different scenarios, adjusted these values to the appropriate date, and synthesised them into a PowerBI report for clear visualisation and interpretation of the benchmarking outputs.\\n\\nSensitivity Analysis\\n\\nClient: Anglian Water (AW)\\n\\nValue: Conducted Monte Carlo simulation and statistical review for over 130 cost curves to estimate the cost modelling uncertainty on £1 billion business plan.\\n\\nDates: Jul 2023 – Sep 2023\\n\\nRole: Data Analyst/Data Scientist\\n\\nDaniel developed a systematic Python-based approach to create customized cost curve models, conduct sensitivity analyses, and perform Monte Carlo Simulations for each set of cost curves provided by AW. The project encompasses a comprehensive desktop analysis aimed at identifying best practices to be adopted by UK water companies. Daniel conducted a statistical review of cost curves using specific metrics, performed Monte-Carlo analysis to estimate the potential impact of changes in project costs on the overall business plan, and subsequently generated P10 and P90 values from the statistical simulation as required by Ofwat. Additionally, he conducted an independent commodity sensitivity review. This in-depth analysis enabled him to assess the influence of various input parameters on TOTEX projections, facilitating a thorough evaluation of potential risks and uncertainties.\\n\\nCapex Master Tracker and Weekly KPI Dashboard\\n\\nClient: The Arch Company\\n\\nValue: Designed and implemented a batch ETL (Extract, Transform, Load) process that extracts data from multiple sources, transforms it as needed, and loads it into the reporting system. This optimised the reporting process, reducing the previously laborious 10-hour task to just 15 minutes of work with a customized and scalable script. This time savings greatly improved efficiency and accuracy in tracking and reporting key metrics.\\n\\nDates: Apr 2023 – Aug 2023\\n\\nRole: Data Engineer\\n\\nDaniel’s role involves collecting, comprehending, aggregating (including data transformation), and reporting data to support the key weekly and monthly milestones for Arch-Co. The primary objective is to update and summarise critical data related to Capex, lettings, terminations, and examinations across the portfolio of assets. This project posed a significant data challenge because the traditional process of updating the Master Tracker was cumbersome and time-consuming due to inconsistent data formats from various data sources within different regions of Network Rail. To address this challenge, a more systematic approach was introduced to accommodate the varying data structures across the schemas.\\n\\nBenchmarking and Curve Library\\n\\nClient: Scottish Water (SW)\\n\\nValue: Optimising the benchmarking approach for clients by utilising AECOM internal mapping system, Python, and SQL server to identify, create and combine multiple relevant cost models into one.\\n\\nDates: Mar 2023 – Jun 2023\\n\\nRole: Analyst, Cost Management\\n\\nDaniel supported SW with external benchmarking for high reputational projects where confidence in their estimates is needed. The project included configuring a SW bespoke benchmarking library and implementation of a systemic approach to benchmarking SW assets. In addition, a bespoke benchmark library is being developed into the BES/BEA system for use by SW estimating and the cost intelligence teams.\\n\\nPR24 Enhancement Benchmarking\\n\\nClient: Anglian Water\\n\\nValue: Systematic approach for data transformation and quality assurance.\\n\\nDates: May 2023 – Jun 2023\\n\\nRole: Data Engineer\\n\\nDaniel provided AWS with external benchmarking aligned to their project and asset list for PR24. He developed Python scripts to compile the output of multiple spreadsheets into one master deliverable sheet. He worked with the estimating team for quality assurance of the benchmark.\\n\\nEstimating and Benchmarking Support (BEA)\\n\\nClient: Scottish Water (SW)\\n\\nValue: Created over 80 cost curves within BEA. Contributed to a collaborative matching exercise and matched the terminology of SW engineering processes against with AECOM benchmarking library.\\n\\nDates: Jan 2023 – Mar 2023\\n\\nRole: Analyst, Cost Management\\n\\nDaniel supported SW with implementing their new benchmarking estimating analysis tool (BEA). This included creating numerous master and modelling datasets based on different query criteria, generating new cost curves within BEA, ensuring the cost models are robust and logical in respect to the statistics data and relevant engineering context.\\n\\nElectronic Permit-to-work System (ePTW), Digital Transformation Project\\n\\nClient: Shell, HK\\n\\nValue: Design and overlook the whole project and acted as a bridge to coordinate between business, operational, and software developer team. Trained up several focal points across different stakeholders, including the peers in mainland China. Continuous maintenance and update for the new system. Managed and analysed various live data by Power BI and report them to senior management team regularly.\\n\\nDates: 2020 - 2021\\n\\nRole: Project Manager\\n\\nDaniel was responsible for the development and creation of a digital platform to replace the traditional permit-to-work system being used in the oil terminal. It is a work authorization software and system that can synchronise operational, maintenance, scheduled and unscheduled work across organizations, provide control over contractors and reduce risk.\\n\\nHazard Emergency Management Plan (HEMP), Emergency Response Plan\\n\\nClient: Shell HK\\n\\nValue: Reviewed existing plans and researched best practices in emergency response. Proposed and implemented an innovative solution, an interactive training program that would educate employees about the emergency response plan in an interactive and engaging way.\\n\\nDates: 2019-2020\\n\\nRole: Emergency Preparedness Program Coordinator\\n\\nA complex infrastructure and a large workforce spread across multiple locations. Daniel was responsible for developing a comprehensive plan that would ensure the safety of employees and minimize the impact of any potential emergency.\\n\\n<!-- PageFooter=\"As a recipient of this personal data, you agree that as a data controller, you are obliged to comply with all applicable privacy laws and regulations, including the General Data Protection Regulation.\" -->\\n')]\n"
     ]
    }
   ],
   "source": [
    "# %pip install --upgrade --quiet  langchain langchain-community azure-ai-documentintelligence\n",
    "\n",
    "from langchain_community.document_loaders import AzureAIDocumentIntelligenceLoader\n",
    "\n",
    "file_path = \"C:/Users/WongD7/Documents/AECOM internal/Wong Daniel_Graduate Consultant_WIP.docx\"  # change this to your own file path\n",
    "endpoint = config[\"AZURE_DOCUMENT_INTELLIGENCE_ENDPOINT\"]\n",
    "key = config[\"AZURE_DOCUMENT_INTELLIGENCE_API_KEY\"]\n",
    "loader = AzureAIDocumentIntelligenceLoader(\n",
    "    api_endpoint=endpoint, api_key=key, file_path=file_path, api_model=\"prebuilt-layout\", mode=\"markdown\"\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "print(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[Document(page_content='Daniel Wong BSc (Hons), MSc\\n\\nGraduate Cost & Carbon Intelligence Consultant\\n\\n| Proposed position on project Bespoke to opportunity we are bidding for | Qualifications BSc (Hons) Environmental & Occupational Safety and Health Year completed: 2019 MSc Computing and Information System (Distinction) Year completed: 2022 | Professional memberships Publications Financial Risk Manager (FRM) Part 1 Certified (GARP) Certified ISO9001 Internal Auditor (HKQAA) Certificate in First Aid & adult CPR & automated external defibrillation (St. John) Completed training for Oracle Primavera P6 | |\\n| - | - | - | - |\\n| Project name Name of project we are bidding for ||||\\n\\nDaniel is a graduate consultant with a passion for innovation across industries. He consistently navigates new challenges with ease, demonstrating an exceptional capacity to adapt swiftly and devise innovative solutions to solve problems. Moreover, Daniel possesses a deep understanding and proficiency in leveraging cutting-edge technologies such as Large Language Models (LLM) and machine learning, further enhancing his capabilities to tackle diverse and complex tasks in the most efficient way as possible.\\n\\nRelevant experience'), Document(page_content=\"Daniel's career began in the oil and gas sector, where he quickly made a name for himself as a corporate HSSE advisor. Throughout his career, he has consistently taken on new challenges and expanded his skill set. This led him to pursue opportunities in a variety of industries, including energy, infrastructure, finance and logistics, where he was able to apply his skills to a range of different challenges.\\n\\nDaniel's exceptional learning abilities have also been an asset in his professional development. He is always eager to take on new opportunities and continuously improve his skills and has pursued advanced education and training in a variety of fields.\\n\\nHe is a highly motivated and results-driven professional who is committed to making a positive impact in his work and community. He is a quick learner and problem solver who is always up for a challenge and eager to help others succeed.\\n\\nKey Skills\\n\\nPython\\n\\nMicrosoft Azure SQL\\n\\nLLM / Machine Learning\\n\\nWeb Development\\n\\nData Analytics & Visualisation\\n\\nProject experience\\n\\nNews Scraping Analytics App\\n\\nPotential Client: Anglian Water\\n\\nValue: Developed a web app to provide potential clients like Anglian Water with a tool to stay updated on the latest news and trends across the web related to their suppliers and focus areas.\"), Document(page_content='Dates: Jan 2024 – Present\\n\\nRole: Full Stack/Web Developer\\n\\nDaniel initiated the project by creating a demo using Dash and later transitioned to Streamlit for the enhanced user interface and full-scale development. Additionally, Daniel integrated an LLM-powered chatbot (Llama2) and advanced RAG (Retrieval Augmented Generation) techniques to deliver relevant and accurate responses based on real-time information scraped from the internet. He also incorporated advanced analysis features such as text summarisation, sentiment analysis, and topic modelling for the scrapped news articles. Furthermore, Daniel implemented efficient data management using an SQL database and explored deployment options on Azure Web App service.\\n\\nMoJ – Asset Data Consolidation and Visualisation\\n\\nClient: Ministry of Justice (MoJ) - Prison Estate\\n\\nValue: Developed a comprehensive tool for consolidating and visualizing asset data to assist MoJ in strategic planning for their prison estates.\\n\\nDates: Mar 2024 – May 2024\\n\\nRole: Analyst, Data Analytics & Visualization'), Document(page_content=\"As the technical key driver, Daniel spearheaded the development of a customized ETL pipeline using Python to consolidate 440 datasets from 110 sites into a unified database. Afterward, he designed a dynamic Power BI dashboard to visualize these data sets, enabling MoJ to easily identify trends and make informed decisions regarding future asset management and capital works. This project showcased his ability to manage large data sets, standardize complex information, and deliver actionable insights through advanced data visualization tools.\\n\\nSmart Buildings Value Framework\\n\\nClient: Defence Infrastructure Organisation\\n\\nValue: Developed a dynamic framework tool that will serve as a useful tool for DIO to explore the potential benefits of adopting smart technologies at differing levels of sophistication.\\n\\nDates: Feb 2024 – Mar 2024\\n\\nRole: Analyst, Cost Management\\n\\nDaniel created a dynamic calculator to evaluate smart technology benefits in building infrastructure. He collaborated closely with stakeholders to meet requirements, designed algorithms to quantify six key benefits (i.e. water, electricity, gas, user experience, cost, and carbon), and utilised Excel's advanced features like VBA and Power Pivot to develop an interactive and scalable dashboard in Excel.\\n\\nOptions Benchmarking\\n\\nClient: Scottish Water\"), Document(page_content=\"Value: Generated high level benchmark values for 7 options proposed for the East Sterling Villages projects, so as to support the client’s decision making on progressing their preferred option.\\n\\nDates: Oct 2023 – Dec 2023\\n\\nRole: Analyst, Cost Management\\n\\nDaniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His tasks included data cleaning, transformation, and the development of a VBA script to systematically benchmark the options. He conducted statistical validation to ensure the accuracy and reliability of the benchmarking process. Additionally, Daniel created a range of output values under different scenarios, adjusted these values to the appropriate date, and synthesised them into a PowerBI report for clear visualisation and interpretation of the benchmarking outputs.\\n\\nSensitivity Analysis\\n\\nClient: Anglian Water (AW)\\n\\nValue: Conducted Monte Carlo simulation and statistical review for over 130 cost curves to estimate the cost modelling uncertainty on £1 billion business plan.\\n\\nDates: Jul 2023 – Sep 2023\\n\\nRole: Data Analyst/Data Scientist\"), Document(page_content='Daniel developed a systematic Python-based approach to create customized cost curve models, conduct sensitivity analyses, and perform Monte Carlo Simulations for each set of cost curves provided by AW. The project encompasses a comprehensive desktop analysis aimed at identifying best practices to be adopted by UK water companies. Daniel conducted a statistical review of cost curves using specific metrics, performed Monte-Carlo analysis to estimate the potential impact of changes in project costs on the overall business plan, and subsequently generated P10 and P90 values from the statistical simulation as required by Ofwat. Additionally, he conducted an independent commodity sensitivity review. This in-depth analysis enabled him to assess the influence of various input parameters on TOTEX projections, facilitating a thorough evaluation of potential risks and uncertainties.\\n\\nCapex Master Tracker and Weekly KPI Dashboard\\n\\nClient: The Arch Company\\n\\nValue: Designed and implemented a batch ETL (Extract, Transform, Load) process that extracts data from multiple sources, transforms it as needed, and loads it into the reporting system. This optimised the reporting process, reducing the previously laborious 10-hour task to just 15 minutes of work with a customized and scalable script. This time savings greatly improved efficiency and accuracy in tracking and reporting key metrics.'), Document(page_content='Dates: Apr 2023 – Aug 2023\\n\\nRole: Data Engineer\\n\\nDaniel’s role involves collecting, comprehending, aggregating (including data transformation), and reporting data to support the key weekly and monthly milestones for Arch-Co. The primary objective is to update and summarise critical data related to Capex, lettings, terminations, and examinations across the portfolio of assets. This project posed a significant data challenge because the traditional process of updating the Master Tracker was cumbersome and time-consuming due to inconsistent data formats from various data sources within different regions of Network Rail. To address this challenge, a more systematic approach was introduced to accommodate the varying data structures across the schemas.\\n\\nBenchmarking and Curve Library\\n\\nClient: Scottish Water (SW)\\n\\nValue: Optimising the benchmarking approach for clients by utilising AECOM internal mapping system, Python, and SQL server to identify, create and combine multiple relevant cost models into one.\\n\\nDates: Mar 2023 – Jun 2023\\n\\nRole: Analyst, Cost Management'), Document(page_content='Daniel supported SW with external benchmarking for high reputational projects where confidence in their estimates is needed. The project included configuring a SW bespoke benchmarking library and implementation of a systemic approach to benchmarking SW assets. In addition, a bespoke benchmark library is being developed into the BES/BEA system for use by SW estimating and the cost intelligence teams.\\n\\nPR24 Enhancement Benchmarking\\n\\nClient: Anglian Water\\n\\nValue: Systematic approach for data transformation and quality assurance.\\n\\nDates: May 2023 – Jun 2023\\n\\nRole: Data Engineer\\n\\nDaniel provided AWS with external benchmarking aligned to their project and asset list for PR24. He developed Python scripts to compile the output of multiple spreadsheets into one master deliverable sheet. He worked with the estimating team for quality assurance of the benchmark.\\n\\nEstimating and Benchmarking Support (BEA)\\n\\nClient: Scottish Water (SW)\\n\\nValue: Created over 80 cost curves within BEA. Contributed to a collaborative matching exercise and matched the terminology of SW engineering processes against with AECOM benchmarking library.\\n\\nDates: Jan 2023 – Mar 2023\\n\\nRole: Analyst, Cost Management'), Document(page_content='Daniel supported SW with implementing their new benchmarking estimating analysis tool (BEA). This included creating numerous master and modelling datasets based on different query criteria, generating new cost curves within BEA, ensuring the cost models are robust and logical in respect to the statistics data and relevant engineering context.\\n\\nElectronic Permit-to-work System (ePTW), Digital Transformation Project\\n\\nClient: Shell, HK\\n\\nValue: Design and overlook the whole project and acted as a bridge to coordinate between business, operational, and software developer team. Trained up several focal points across different stakeholders, including the peers in mainland China. Continuous maintenance and update for the new system. Managed and analysed various live data by Power BI and report them to senior management team regularly.\\n\\nDates: 2020 - 2021\\n\\nRole: Project Manager\\n\\nDaniel was responsible for the development and creation of a digital platform to replace the traditional permit-to-work system being used in the oil terminal. It is a work authorization software and system that can synchronise operational, maintenance, scheduled and unscheduled work across organizations, provide control over contractors and reduce risk.\\n\\nHazard Emergency Management Plan (HEMP), Emergency Response Plan\\n\\nClient: Shell HK'), Document(page_content='Value: Reviewed existing plans and researched best practices in emergency response. Proposed and implemented an innovative solution, an interactive training program that would educate employees about the emergency response plan in an interactive and engaging way.\\n\\nDates: 2019-2020\\n\\nRole: Emergency Preparedness Program Coordinator\\n\\nA complex infrastructure and a large workforce spread across multiple locations. Daniel was responsible for developing a comprehensive plan that would ensure the safety of employees and minimize the impact of any potential emergency.\\n\\n<!-- PageFooter=\"As a recipient of this personal data, you agree that as a data controller, you are obliged to comply with all applicable privacy laws and regulations, including the General Data Protection Regulation.\" -->')]\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "# this method is better than loading a tiktoken splitter directly, which will chunk in the middle of sentences\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    model_name=\"gpt-4\",\n",
    "    chunk_size=250,\n",
    "    chunk_overlap=0,\n",
    ")\n",
    "\n",
    "# page_contents = [doc.page_content for doc in documents]     # convert the list of document objects to a list of strings\n",
    "# docs = text_splitter.create_documents(page_contents)        # this method can create a list of objects with page_content attribute, which is required by the AzureSearch object\n",
    "docs = text_splitter.split_documents(documents)       # this method will create a list of strings, which is not suitable for the AzureSearch object\n",
    "print(len(docs))\n",
    "print(docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NjJiMDVjMGUtOTRlNy00ZmE0LTlhYzctMjNjYTkzMGVmMjI1',\n",
       " 'OWY2ZjJhODAtMmFiMS00ODdiLThiMDQtMWYyMGM5MjY2NGE0',\n",
       " 'MTRmOTBiOTAtMGNkNC00OWMxLWJiMDctNzJiZTE4ODVlOWMz',\n",
       " 'YTM0Mzc0OWItZTQwZi00YmM5LTg2ZjYtNGUwNTg5MGIxMzk1',\n",
       " 'NTJlZmI0YmItM2ViZi00MjEwLWIyYTQtZjVlMGY4ZmEwN2Q3',\n",
       " 'ZWRkNmM0NWUtZmI1OC00ZjU1LTg1ZGItOWNjNmJjYjFmOWI5',\n",
       " 'ZjhiZjUwZDUtZThmMC00OWQzLTg5NjItMTk4NzZjMDVmMTJh',\n",
       " 'NjNmZWE5OTEtZDRiOS00ZTMwLTgzMzctMWQ0ZThlOGI2ZjIy',\n",
       " 'ODliNmQzYTYtNTM2ZC00MzQzLTgyNGEtYWNiYWFjOTgwMzlj',\n",
       " 'ZTc3M2JjOWUtYzdiMy00ZjIyLTk5OTQtOGJmYzI2ODc3ZmEz']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_store.add_documents(documents=docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His\"),\n",
       " Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His tasks included data cleaning, transformation, and the development of a VBA script to systematically benchmark the options. He conducted statistical validation to ensure the accuracy and reliability of the benchmarking process. Additionally, Daniel created a range of output values under different scenarios, adjusted these values to the appropriate date, and synthesised them into a PowerBI report for clear visualisation and interpretation of the benchmarking outputs.\"),\n",
       " Document(page_content=\"Daniel's career began in the oil and gas sector, where he quickly made a name for himself as a corporate HSSE advisor. Throughout his career, he has consistently taken on new challenges and expanded his skill set. This led him to pursue opportunities in a variety of industries, including energy, infrastructure, finance and logistics, where he was able to apply his skills to a range of different challenges.\\n\\nDaniel's exceptional learning abilities have also been an asset in his professional development. He is always eager to take on new opportunities and continuously improve his skills and has pursued advanced education and training in a variety of fields.\\n\\nHe is a highly motivated and results-driven professional who is committed to making a positive impact in his work and community. He is a quick learner and problem solver who is always up for a challenge and eager to help others succeed.\\n\\nKey Skills\\n\\nPython\\n\\nMicrosoft Azure SQL\\n\\nLLM / Machine Learning\\n\\nWeb Development\\n\\nData Analytics & Visualisation\\n\\nProject experience\\n\\nNews Scraping Analytics App\\n\\nPotential Client: Anglian Water\\n\\nValue: Developed a web app to provide potential clients like Anglian Water with a tool to stay updated on the latest news and trends across the web related to their suppliers and focus areas.\")]"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a similarity search\n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What did Daniel do at AECOM?\",\n",
    "    k=3,\n",
    "    search_type=\"similarity\",\n",
    ")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His\"),\n",
       " Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His tasks included data cleaning, transformation, and the development of a VBA script to systematically benchmark the options. He conducted statistical validation to ensure the accuracy and reliability of the benchmarking process. Additionally, Daniel created a range of output values under different scenarios, adjusted these values to the appropriate date, and synthesised them into a PowerBI report for clear visualisation and interpretation of the benchmarking outputs.\"),\n",
       " Document(page_content='analysis aimed at identifying best practices to be adopted by UK water companies. Daniel conducted a statistical review of cost curves using specific')]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a hybrid search \n",
    "docs = vector_store.similarity_search(\n",
    "    query=\"What did Daniel do at AECOM?\",\n",
    "    k=3,\n",
    "    search_type=\"hybrid\",\n",
    ")\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His\"),\n",
       " Document(page_content=\"Daniel was responsible for designing and implementing a mapping approach to compare Scottish Water's provided models with AECOM internal models. His tasks included data cleaning, transformation, and the development of a VBA script to systematically benchmark the options. He conducted statistical validation to ensure the accuracy and reliability of the benchmarking process. Additionally, Daniel created a range of output values under different scenarios, adjusted these values to the appropriate date, and synthesised them into a PowerBI report for clear visualisation and interpretation of the benchmarking outputs.\"),\n",
       " Document(page_content=\"Daniel's career began in the oil and gas sector, where he quickly made a name for himself as a corporate HSSE advisor. Throughout his career, he has consistently taken on new challenges and expanded his skill set. This led him to pursue opportunities in a variety of industries, including energy, infrastructure, finance and logistics, where he was able to apply his skills to a range of different challenges.\\n\\nDaniel's exceptional learning abilities have also been an asset in his professional development. He is always eager to take on new opportunities and continuously improve his skills and has pursued advanced education and training in a variety of fields.\\n\\nHe is a highly motivated and results-driven professional who is committed to making a positive impact in his work and community. He is a quick learner and problem solver who is always up for a challenge and eager to help others succeed.\\n\\nKey Skills\\n\\nPython\\n\\nMicrosoft Azure SQL\\n\\nLLM / Machine Learning\\n\\nWeb Development\\n\\nData Analytics & Visualisation\\n\\nProject experience\\n\\nNews Scraping Analytics App\\n\\nPotential Client: Anglian Water\\n\\nValue: Developed a web app to provide potential clients like Anglian Water with a tool to stay updated on the latest news and trends across the web related to their suppliers and focus areas.\")]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
